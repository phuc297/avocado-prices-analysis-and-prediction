{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold;font-size:40px\">Introduction</div>\n",
    "\n",
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><ul style=\"font-size:20px;\">\n",
    " Hello everyone!\n",
    ">    \n",
    ">    I believe that the best approach to learn is to learn what you're passionate about.\n",
    ">So, I'm passionate about healthy food 🥑 Let's learn together and investigate avocado prices!\n",
    ">We will discover this question with the use of EDA (the second step) and ML methods (the third step).\n",
    ">    \n",
    ">Many thanks to the сreator of this dataset,\n",
    "><br>If you like this project, please, support me - UPvote!😃\n",
    "\n",
    "<center><img src=\"https://i.pinimg.com/564x/cf/c4/f1/cfc4f1cfd6d9af866b8cd3ace353b6d5.jpg\" width=300></center>\n",
    "\n",
    "\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"font-weight: bold;font-size:30px\">Data columns description & libraries</div>\n",
    "\n",
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><ul style=\"font-size:18px;\">\n",
    "<li> Date - The date of the observation</li>\n",
    "<li> AveragePrice - the average price of a single avocado</li>\n",
    "<li> type - conventional or organic</li>\n",
    "<li> year - the year</li>\n",
    "<li> Region - the city or region of the observation</li>\n",
    "<li> Total Volume - Total number of avocados sold</li>\n",
    "<li> 4046 - Total number of avocados with PLU 4046 sold</li>\n",
    "<li> 4225 - Total number of avocados with PLU 4225 sold</li>\n",
    "<li> 4770 - Total number of avocados with PLU 4770 sold</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<br><div style=\"font-weight: bold;font-size:30px\">Table of Contents</div>\n",
    "\n",
    "* [Step 1: Examining Data](#section-two)\n",
    "    - [Basic information](#sub-21)\n",
    "    - [Data preproccessing](#sub-22)\n",
    "    - [Making additional columns](#sub-23)\n",
    "\n",
    "* [Step 2: EDA](#section-three)\n",
    "    - [2.1 Research of daily, monthly and per year average price](#sub-31)\n",
    "    - [2.2 Examining features](#sub-32)\n",
    "    - [2.3 The correlation matrix](#sub-33)\n",
    "    \n",
    "* [Step 3: Regression](#section-four)\n",
    "    - [2.1 Research of daily, monthly and per year average price](#sub-31)\n",
    "    - [2.2 Examining features](#sub-32)\n",
    "    - [2.3 The correlation matrix](#sub-33)\n",
    "* [Overall Conclusion](#section-end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-06T16:03:54.602347Z",
     "iopub.status.busy": "2021-09-06T16:03:54.601949Z",
     "iopub.status.idle": "2021-09-06T16:03:54.916735Z",
     "shell.execute_reply": "2021-09-06T16:03:54.915862Z",
     "shell.execute_reply.started": "2021-09-06T16:03:54.602299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydotplus in c:\\users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\lib\\site-packages (from pydotplus) (3.1.4)\n"
     ]
    }
   ],
   "source": [
    "#Importing Requierd Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# for Interactive Shells\n",
    "from IPython.display import display\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "#removing warnings\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "# to depict tree_prediction\n",
    "! pip install pydotplus\n",
    "from pydotplus import graph_from_dot_data\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-two\"></a>\n",
    "<div style=\"font-weight: bold;font-size:30px\">Step 1: Examining Data</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sub-21\"></a>\n",
    "<div style=\"font-weight: bold;font-size:20px\">1.1 Basic information</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:03.561688Z",
     "iopub.status.busy": "2021-09-06T16:04:03.561158Z",
     "iopub.status.idle": "2021-09-06T16:04:03.729687Z",
     "shell.execute_reply": "2021-09-06T16:04:03.72857Z",
     "shell.execute_reply.started": "2021-09-06T16:04:03.561645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining \"Avocado dataset\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "\n",
       "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "\n",
       "   year  region  \n",
       "0  2015  Albany  \n",
       "1  2015  Albany  \n",
       "2  2015  Albany  \n",
       "3  2015  Albany  \n",
       "4  2015  Albany  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    18249 non-null  int64  \n",
      " 1   Date          18249 non-null  object \n",
      " 2   AveragePrice  18249 non-null  float64\n",
      " 3   Total Volume  18249 non-null  float64\n",
      " 4   4046          18249 non-null  float64\n",
      " 5   4225          18249 non-null  float64\n",
      " 6   4770          18249 non-null  float64\n",
      " 7   Total Bags    18249 non-null  float64\n",
      " 8   Small Bags    18249 non-null  float64\n",
      " 9   Large Bags    18249 non-null  float64\n",
      " 10  XLarge Bags   18249 non-null  float64\n",
      " 11  type          18249 non-null  object \n",
      " 12  year          18249 non-null  int64  \n",
      " 13  region        18249 non-null  object \n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18249.000000</td>\n",
       "      <td>18249</td>\n",
       "      <td>18249.000000</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>18249.000000</td>\n",
       "      <td>18249</td>\n",
       "      <td>18249.000000</td>\n",
       "      <td>18249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>conventional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.232232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.405978</td>\n",
       "      <td>8.506440e+05</td>\n",
       "      <td>2.930084e+05</td>\n",
       "      <td>2.951546e+05</td>\n",
       "      <td>2.283974e+04</td>\n",
       "      <td>2.396392e+05</td>\n",
       "      <td>1.821947e+05</td>\n",
       "      <td>5.433809e+04</td>\n",
       "      <td>3106.426507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.147899</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.481045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.402677</td>\n",
       "      <td>3.453545e+06</td>\n",
       "      <td>1.264989e+06</td>\n",
       "      <td>1.204120e+06</td>\n",
       "      <td>1.074641e+05</td>\n",
       "      <td>9.862424e+05</td>\n",
       "      <td>7.461785e+05</td>\n",
       "      <td>2.439660e+05</td>\n",
       "      <td>17692.894652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>8.456000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.083858e+04</td>\n",
       "      <td>8.540700e+02</td>\n",
       "      <td>3.008780e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.088640e+03</td>\n",
       "      <td>2.849420e+03</td>\n",
       "      <td>1.274700e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.073768e+05</td>\n",
       "      <td>8.645300e+03</td>\n",
       "      <td>2.906102e+04</td>\n",
       "      <td>1.849900e+02</td>\n",
       "      <td>3.974383e+04</td>\n",
       "      <td>2.636282e+04</td>\n",
       "      <td>2.647710e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>4.329623e+05</td>\n",
       "      <td>1.110202e+05</td>\n",
       "      <td>1.502069e+05</td>\n",
       "      <td>6.243420e+03</td>\n",
       "      <td>1.107834e+05</td>\n",
       "      <td>8.333767e+04</td>\n",
       "      <td>2.202925e+04</td>\n",
       "      <td>132.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>6.250565e+07</td>\n",
       "      <td>2.274362e+07</td>\n",
       "      <td>2.047057e+07</td>\n",
       "      <td>2.546439e+06</td>\n",
       "      <td>1.937313e+07</td>\n",
       "      <td>1.338459e+07</td>\n",
       "      <td>5.719097e+06</td>\n",
       "      <td>551693.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0        Date  AveragePrice  Total Volume          4046  \\\n",
       "count   18249.000000       18249  18249.000000  1.824900e+04  1.824900e+04   \n",
       "unique           NaN         169           NaN           NaN           NaN   \n",
       "top              NaN  2015-12-27           NaN           NaN           NaN   \n",
       "freq             NaN         108           NaN           NaN           NaN   \n",
       "mean       24.232232         NaN      1.405978  8.506440e+05  2.930084e+05   \n",
       "std        15.481045         NaN      0.402677  3.453545e+06  1.264989e+06   \n",
       "min         0.000000         NaN      0.440000  8.456000e+01  0.000000e+00   \n",
       "25%        10.000000         NaN      1.100000  1.083858e+04  8.540700e+02   \n",
       "50%        24.000000         NaN      1.370000  1.073768e+05  8.645300e+03   \n",
       "75%        38.000000         NaN      1.660000  4.329623e+05  1.110202e+05   \n",
       "max        52.000000         NaN      3.250000  6.250565e+07  2.274362e+07   \n",
       "\n",
       "                4225          4770    Total Bags    Small Bags    Large Bags  \\\n",
       "count   1.824900e+04  1.824900e+04  1.824900e+04  1.824900e+04  1.824900e+04   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean    2.951546e+05  2.283974e+04  2.396392e+05  1.821947e+05  5.433809e+04   \n",
       "std     1.204120e+06  1.074641e+05  9.862424e+05  7.461785e+05  2.439660e+05   \n",
       "min     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%     3.008780e+03  0.000000e+00  5.088640e+03  2.849420e+03  1.274700e+02   \n",
       "50%     2.906102e+04  1.849900e+02  3.974383e+04  2.636282e+04  2.647710e+03   \n",
       "75%     1.502069e+05  6.243420e+03  1.107834e+05  8.333767e+04  2.202925e+04   \n",
       "max     2.047057e+07  2.546439e+06  1.937313e+07  1.338459e+07  5.719097e+06   \n",
       "\n",
       "          XLarge Bags          type          year  region  \n",
       "count    18249.000000         18249  18249.000000   18249  \n",
       "unique            NaN             2           NaN      54  \n",
       "top               NaN  conventional           NaN  Albany  \n",
       "freq              NaN          9126           NaN     338  \n",
       "mean      3106.426507           NaN   2016.147899     NaN  \n",
       "std      17692.894652           NaN      0.939938     NaN  \n",
       "min          0.000000           NaN   2015.000000     NaN  \n",
       "25%          0.000000           NaN   2015.000000     NaN  \n",
       "50%          0.000000           NaN   2016.000000     NaN  \n",
       "75%        132.500000           NaN   2017.000000     NaN  \n",
       "max     551693.650000           NaN   2018.000000     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Date', 'AveragePrice', 'Total Volume', '4046', '4225',\n",
       "       '4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'type',\n",
       "       'year', 'region'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicates.\n",
      "There are no missing values in \"Avocado dataset\".\n",
      "['2015-12-27' '2015-12-20' '2015-12-13' '2015-12-06' '2015-11-29'\n",
      " '2015-11-22' '2015-11-15' '2015-11-08' '2015-11-01' '2015-10-25'\n",
      " '2015-10-18' '2015-10-11' '2015-10-04' '2015-09-27' '2015-09-20'\n",
      " '2015-09-13' '2015-09-06' '2015-08-30' '2015-08-23' '2015-08-16'\n",
      " '2015-08-09' '2015-08-02' '2015-07-26' '2015-07-19' '2015-07-12'\n",
      " '2015-07-05' '2015-06-28' '2015-06-21' '2015-06-14' '2015-06-07'\n",
      " '2015-05-31' '2015-05-24' '2015-05-17' '2015-05-10' '2015-05-03'\n",
      " '2015-04-26' '2015-04-19' '2015-04-12' '2015-04-05' '2015-03-29'\n",
      " '2015-03-22' '2015-03-15' '2015-03-08' '2015-03-01' '2015-02-22'\n",
      " '2015-02-15' '2015-02-08' '2015-02-01' '2015-01-25' '2015-01-18'\n",
      " '2015-01-11' '2015-01-04' '2016-12-25' '2016-12-18' '2016-12-11'\n",
      " '2016-12-04' '2016-11-27' '2016-11-20' '2016-11-13' '2016-11-06'\n",
      " '2016-10-30' '2016-10-23' '2016-10-16' '2016-10-09' '2016-10-02'\n",
      " '2016-09-25' '2016-09-18' '2016-09-11' '2016-09-04' '2016-08-28'\n",
      " '2016-08-21' '2016-08-14' '2016-08-07' '2016-07-31' '2016-07-24'\n",
      " '2016-07-17' '2016-07-10' '2016-07-03' '2016-06-26' '2016-06-19'\n",
      " '2016-06-12' '2016-06-05' '2016-05-29' '2016-05-22' '2016-05-15'\n",
      " '2016-05-08' '2016-05-01' '2016-04-24' '2016-04-17' '2016-04-10'\n",
      " '2016-04-03' '2016-03-27' '2016-03-20' '2016-03-13' '2016-03-06'\n",
      " '2016-02-28' '2016-02-21' '2016-02-14' '2016-02-07' '2016-01-31'\n",
      " '2016-01-24' '2016-01-17' '2016-01-10' '2016-01-03' '2017-12-31'\n",
      " '2017-12-24' '2017-12-17' '2017-12-10' '2017-12-03' '2017-11-26'\n",
      " '2017-11-19' '2017-11-12' '2017-11-05' '2017-10-29' '2017-10-22'\n",
      " '2017-10-15' '2017-10-08' '2017-10-01' '2017-09-24' '2017-09-17'\n",
      " '2017-09-10' '2017-09-03' '2017-08-27' '2017-08-20' '2017-08-13'\n",
      " '2017-08-06' '2017-07-30' '2017-07-23' '2017-07-16' '2017-07-09'\n",
      " '2017-07-02' '2017-06-25' '2017-06-18' '2017-06-11' '2017-06-04'\n",
      " '2017-05-28' '2017-05-21' '2017-05-14' '2017-05-07' '2017-04-30'\n",
      " '2017-04-23' '2017-04-16' '2017-04-09' '2017-04-02' '2017-03-26'\n",
      " '2017-03-19' '2017-03-12' '2017-03-05' '2017-02-26' '2017-02-19'\n",
      " '2017-02-12' '2017-02-05' '2017-01-29' '2017-01-22' '2017-01-15'\n",
      " '2017-01-08' '2017-01-01' '2018-03-25' '2018-03-18' '2018-03-11'\n",
      " '2018-03-04' '2018-02-25' '2018-02-18' '2018-02-11' '2018-02-04'\n",
      " '2018-01-28' '2018-01-21' '2018-01-14' '2018-01-07']\n",
      "['conventional' 'organic']\n",
      "['Albany' 'Atlanta' 'BaltimoreWashington' 'Boise' 'Boston'\n",
      " 'BuffaloRochester' 'California' 'Charlotte' 'Chicago' 'CincinnatiDayton'\n",
      " 'Columbus' 'DallasFtWorth' 'Denver' 'Detroit' 'GrandRapids' 'GreatLakes'\n",
      " 'HarrisburgScranton' 'HartfordSpringfield' 'Houston' 'Indianapolis'\n",
      " 'Jacksonville' 'LasVegas' 'LosAngeles' 'Louisville' 'MiamiFtLauderdale'\n",
      " 'Midsouth' 'Nashville' 'NewOrleansMobile' 'NewYork' 'Northeast'\n",
      " 'NorthernNewEngland' 'Orlando' 'Philadelphia' 'PhoenixTucson'\n",
      " 'Pittsburgh' 'Plains' 'Portland' 'RaleighGreensboro' 'RichmondNorfolk'\n",
      " 'Roanoke' 'Sacramento' 'SanDiego' 'SanFrancisco' 'Seattle'\n",
      " 'SouthCarolina' 'SouthCentral' 'Southeast' 'Spokane' 'StLouis' 'Syracuse'\n",
      " 'Tampa' 'TotalUS' 'West' 'WestTexNewMexico']\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "try:\n",
    "    df = pd.read_csv('/kaggle/input/avocado-prices/avocado.csv')\n",
    "except:\n",
    "    df = pd.read_csv('data/avocado.csv')\n",
    "    \n",
    "#making a function for examining data\n",
    "def data_research(data, data_name='data'):\n",
    "    #basic\n",
    "    print(f'Examining \"{data_name}\"')\n",
    "    display(data.head())\n",
    "    display(data.info())\n",
    "    display(data.describe( include='all'))\n",
    "    display(data.columns)\n",
    "    \n",
    "    #duplicates\n",
    "    duplicates = data.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print('There are no duplicated entries.')\n",
    "    else:\n",
    "        print(f'There are {duplicates} duplicates.')\n",
    "        \n",
    "    #missing\n",
    "    data_missing = pd.DataFrame(round(data.isnull().sum() / data.shape[0] * 100, 2))\n",
    "    if data_missing[0].sum() > 0:\n",
    "        print(f'Missing values in the \"{data_name}\":')\n",
    "        data_missing.plot(kind='bar')\n",
    "    else:\n",
    "        print(f'There are no missing values in \"{data_name}\".')\n",
    "    \n",
    "    #unique values\n",
    "    for i in data.columns:\n",
    "        if data[i].dtype == 'object' or data[i].dtype == 'str':\n",
    "            print(data[i].unique())\n",
    "    \n",
    "data_research(df, data_name='Avocado dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><div style=\"font-weight: bold;font-size:20px\">Observations</div>\n",
    "><ul style=\"font-size:18px;\">\n",
    "><center><img src=\"https://i.pinimg.com/originals/c2/1e/cb/c21ecb47122ea4d8eeab4d9ae968cc36.jpg\", width=650></center>\n",
    "We've examined data:\n",
    "<br>- There are 18249 entries and 14 columns, one column is an index, so it is needed to drop it;\n",
    "<br>- No missing or duplicated values and errors (at the first glance), all unique values are correct and don't repeat;\n",
    "<br>- There are some columns, which datatypes are should be changed.<br>\n",
    "At the next step we'll study and preprocess outliers, rename column names and change datatypes.\n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sub-22\"></a>\n",
    "<div style=\"font-weight: bold;font-size:20px\">1.2 Data preproccessing</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold;font-size:16px\">1.2.1 Renaming columns and drop the unecessary one</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:07.376873Z",
     "iopub.status.busy": "2021-09-06T16:04:07.376513Z",
     "iopub.status.idle": "2021-09-06T16:04:07.386647Z",
     "shell.execute_reply": "2021-09-06T16:04:07.385358Z",
     "shell.execute_reply.started": "2021-09-06T16:04:07.37684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'averageprice', 'total volume', '4046', '4225', '4770',\n",
       "       'total bags', 'small bags', 'large bags', 'xlarge bags', 'type', 'year',\n",
       "       'region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.drop('unnamed: 0', axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold;font-size:16px\">1.2.2 Changing data types</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:08.776806Z",
     "iopub.status.busy": "2021-09-06T16:04:08.776368Z",
     "iopub.status.idle": "2021-09-06T16:04:08.808507Z",
     "shell.execute_reply": "2021-09-06T16:04:08.807786Z",
     "shell.execute_reply.started": "2021-09-06T16:04:08.776769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          18249 non-null  datetime64[ns]\n",
      " 1   averageprice  18249 non-null  float64       \n",
      " 2   total volume  18249 non-null  float64       \n",
      " 3   4046          18249 non-null  float64       \n",
      " 4   4225          18249 non-null  float64       \n",
      " 5   4770          18249 non-null  float64       \n",
      " 6   total bags    18249 non-null  float64       \n",
      " 7   small bags    18249 non-null  float64       \n",
      " 8   large bags    18249 non-null  float64       \n",
      " 9   xlarge bags   18249 non-null  float64       \n",
      " 10  type          18249 non-null  category      \n",
      " 11  year          18249 non-null  int64         \n",
      " 12  region        18249 non-null  category      \n",
      "dtypes: category(2), datetime64[ns](1), float64(9), int64(1)\n",
      "memory usage: 1.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if i == 'date':\n",
    "        df[i] = df[i].astype('datetime64[ns]')\n",
    "    elif df[i].dtype == 'object':\n",
    "        df[i] = df[i].astype('category')\n",
    "\n",
    "numeric_columns = ['averageprice', 'total volume',\n",
    "                   '4046', '4225', '4770',\n",
    "                   'total bags', 'small bags',\n",
    "                   'large bags', 'xlarge bags']\n",
    "categorical_columns = ['region', 'type']\n",
    "data_columns = ['data', 'year']\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold;font-size:16px\">1.2.3 Getting known with the kind of distrubutions</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:16.549712Z",
     "iopub.status.busy": "2021-09-06T16:04:16.549178Z",
     "iopub.status.idle": "2021-09-06T16:04:20.703889Z",
     "shell.execute_reply": "2021-09-06T16:04:20.702839Z",
     "shell.execute_reply.started": "2021-09-06T16:04:16.549675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# distributions\n",
    "def dist_custom(dataset, columns_list, rows, cols, suptitle):\n",
    "    fig, axs = plt.subplots(rows, cols,figsize=(16,16))\n",
    "    fig.suptitle(suptitle,y=0.92, size=16)\n",
    "    axs = axs.flatten()\n",
    "    for i, data in enumerate(columns_list):\n",
    "        sns.distplot(dataset[data], ax=axs[i])\n",
    "        axs[i].set_title(data + ', skewness is '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))\n",
    "        \n",
    "dist_custom(dataset=df, columns_list=numeric_columns, rows=3, cols=3, suptitle='Distibution for each variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:16px\">\n",
    "<b>Conclusion:</b> all features are skewed to the left, there is no Normal Distribution.\n",
    "\n",
    "Let's examine outliers with the use of boxplots.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:26.32069Z",
     "iopub.status.busy": "2021-09-06T16:04:26.320311Z",
     "iopub.status.idle": "2021-09-06T16:04:27.487894Z",
     "shell.execute_reply": "2021-09-06T16:04:27.4868Z",
     "shell.execute_reply.started": "2021-09-06T16:04:26.320657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# outliers\n",
    "def boxplots_custom(dataset, columns_list, rows, cols, suptitle):\n",
    "    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(16,12))\n",
    "    fig.suptitle(suptitle,y=0.93, size=16)\n",
    "    axs = axs.flatten()\n",
    "    for i, data in enumerate(columns_list):\n",
    "        if i % 3 == 0:\n",
    "            axs[i].set_ylabel('The number of entries')\n",
    "        sns.boxplot( data=dataset[data], orient='h', ax=axs[i])\n",
    "        axs[i].set_title(data)\n",
    "        \n",
    "boxplots_custom(dataset=df, columns_list=numeric_columns, rows=3, cols=3, suptitle='Boxplots before deleting outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"font-size:16px\">For Skewed distributions we'll use Inter-Quartile Range (IQR) proximity rule.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:36.113388Z",
     "iopub.status.busy": "2021-09-06T16:04:36.113003Z",
     "iopub.status.idle": "2021-09-06T16:04:36.141588Z",
     "shell.execute_reply": "2021-09-06T16:04:36.140515Z",
     "shell.execute_reply.started": "2021-09-06T16:04:36.113347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we will get IQR for each column\n",
      " averageprice         0.56\n",
      "total volume    422123.71\n",
      "4046            110166.13\n",
      "4225            147198.08\n",
      "4770              6243.42\n",
      "total bags      105694.73\n",
      "small bags       80488.25\n",
      "large bags       21901.78\n",
      "xlarge bags        132.50\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11538, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deleting outliers\n",
    "Q1 = df[numeric_columns].quantile(0.25)\n",
    "Q3 = df[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print('Here we will get IQR for each column\\n',IQR)\n",
    "\n",
    "df_filtered = df[~((df[numeric_columns] < (Q1 - 1.5 * IQR)) |(df[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "display(df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:38.820457Z",
     "iopub.status.busy": "2021-09-06T16:04:38.820106Z",
     "iopub.status.idle": "2021-09-06T16:04:39.808625Z",
     "shell.execute_reply": "2021-09-06T16:04:39.807447Z",
     "shell.execute_reply.started": "2021-09-06T16:04:38.820426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "boxplots_custom(dataset=df_filtered, \n",
    "                columns_list=numeric_columns, \n",
    "                rows=3, cols=3, suptitle='Boxplots after deleting outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><div style=\"font-weight: bold;font-size:20px\">Observations</div>\n",
    "><ul style=\"font-size:18px;\">\n",
    ">\n",
    ">Looks much better now! But nevertheless we see some outliers even in filtered data. It will be great to scale the features at the step of building model.\n",
    "We'll use filtered data further\n",
    "> \n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sub-23\"></a>\n",
    "<div style=\"font-weight: bold;font-size:20px\">1.3 Making additional columns to filtered data</div>\n",
    "\n",
    "We already have information about day and year of price scanning, nor let's add additional columns for the further cohort research:\n",
    "- week;\n",
    "- month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:43.652873Z",
     "iopub.status.busy": "2021-09-06T16:04:43.652506Z",
     "iopub.status.idle": "2021-09-06T16:04:43.691715Z",
     "shell.execute_reply": "2021-09-06T16:04:43.690675Z",
     "shell.execute_reply.started": "2021-09-06T16:04:43.652841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast DatetimeArray to dtype datetime64[M]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[M]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[W]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m bins \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.48\u001b[39m, \u001b[38;5;241m1.52\u001b[39m, \u001b[38;5;241m1.78\u001b[39m, \u001b[38;5;241m1.9\u001b[39m, \u001b[38;5;241m2.49\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:739\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, PeriodDtype):\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_period(freq\u001b[38;5;241m=\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfreq)\n\u001b[1;32m--> 739\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtl\u001b[38;5;241m.\u001b[39mDatetimeLikeArrayMixin\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m, dtype, copy)\n",
      "File \u001b[1;32mc:\\Users\\dhfuc\\anaconda3\\envs\\pattern_reg_env\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:494\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype) \u001b[38;5;129;01mor\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;66;03m# disallow conversion between datetime/timedelta,\u001b[39;00m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# and conversions for any datetimelike to float\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot cast DatetimeArray to dtype datetime64[M]"
     ]
    }
   ],
   "source": [
    "df_filtered['month'] = df_filtered['date'].astype('datetime64[M]')\n",
    "df_filtered['week'] = df_filtered['date'].astype('datetime64[W]')\n",
    "bins = [0.48, 1.52, 1.78, 1.9, 2.49]\n",
    "labels = [\"low\",\"mean\",\"high\",'expensive']\n",
    "df_filtered['price_types'] = pd.cut(df['averageprice'], bins=bins, labels=labels)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><div style=\"font-weight: bold;font-size:20px\">Conclusion:</div>\n",
    "><ul style=\"font-size:18px;\">\n",
    "> At this stage:\n",
    "><li> examined the data;</li>\n",
    "><li> renamed column name and drop the unecessary column 'Unnamed: 0';</li>\n",
    "><li> changed dtypes;</li>\n",
    "><li> observed the kind of disributions and calculated the skewness value for each numeric column;</li>\n",
    "><li> plotted boxcharts before and after removing outliers;</li>\n",
    "><li> added new columns for the further research.</li>\n",
    ">Now we're going to make Exploratory Data Analysis➡\n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-three\"></a>\n",
    "<div style=\"font-weight: bold;font-size:30px\">Step 2: EDA</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sub-31\"></a>\n",
    "><div style=\"font-weight: bold;font-size:20px\">2.1 Research of daily, monthly and per year average price</div>\n",
    "><div style=\"font-size:16px\">\n",
    "Let's create new dataset with avarage avocado price per day, month and year. After that we'll create lineplots with the use of plotly.express and analyze it</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:04:47.080789Z",
     "iopub.status.busy": "2021-09-06T16:04:47.080432Z",
     "iopub.status.idle": "2021-09-06T16:04:47.180833Z",
     "shell.execute_reply": "2021-09-06T16:04:47.179708Z",
     "shell.execute_reply.started": "2021-09-06T16:04:47.080756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize figure with subplots\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2, subplot_titles=(\"Daily average prices\", \"Weekly average prices\",\n",
    "                                    \"Monthly average prices\", \"Average prices per years\")\n",
    "                                        )\n",
    "\n",
    "datasets = []\n",
    "for i in ['date','week','month','year']:\n",
    "    datasets.append(round(df_filtered.groupby(i)['averageprice'].mean().reset_index(),3))\n",
    "r, c = 1,1 #rows, cols\n",
    "    \n",
    "for i, d in enumerate(datasets):\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x=d.iloc[:,0], y=d['averageprice']), row=r, col=c)\n",
    "    fig.update_xaxes(title_text='Per ' + d.iloc[:,0].name,row=r, col=c)\n",
    "    fig.update_yaxes(title_text=\"The sum of avarage price\", row=r, col=c)\n",
    "    if i == 1:\n",
    "        r, c = 2, 1\n",
    "    else:\n",
    "        c += 1\n",
    "    \n",
    "# Update title and height\n",
    "fig.update_layout(showlegend=False, title_text=\"Customizing Subplot Axes\", height=700)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:02:02.02368Z",
     "iopub.status.busy": "2021-09-06T16:02:02.023242Z",
     "iopub.status.idle": "2021-09-06T16:02:02.123517Z",
     "shell.execute_reply": "2021-09-06T16:02:02.122337Z",
     "shell.execute_reply.started": "2021-09-06T16:02:02.023633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize figure with subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, subplot_titles=(\"Daily average prices\", \n",
    "                                    \"Monthly average prices\"))\n",
    "\n",
    "datasets = []\n",
    "for i in ['date','month']:\n",
    "    for j in ['conventional', 'organic']:\n",
    "        datasets.append(round(df_filtered.query('type == @j').groupby(i)['averageprice'].mean().reset_index(),3))\n",
    "r, c = 1,1\n",
    "legend_ = ['conventional', 'organic']\n",
    "for i, d in enumerate(datasets):\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x=d.iloc[:,0], y=d['averageprice'], name=legend_[i%2]+' per ' + d.iloc[:,0].name), row=r, col=c)\n",
    "    fig.update_xaxes(title_text='Per ' + d.iloc[:,0].name,row=r, col=c)\n",
    "    fig.update_yaxes(title_text=\"The sum of avarage price\", row=r, col=c)\n",
    "    if i == 1:\n",
    "        c += 1\n",
    "    \n",
    "# Update title and height\n",
    "fig.update_layout(showlegend=True, title_text=\"Daily and monthly avarage prices for conventional and organic types\", height=700)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><div style=\"font-weight: bold;font-size:20px\">Observations:</div>\n",
    "><ul style=\"font-size:18px;\">\n",
    " From the lineplots above:\n",
    "><li>At the daily and monthly average price we see  a decline in price in January 2016-2017 y. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops; </li>\n",
    "><li>At the average price per year chart we see a steady decline from 2015 to 2016 y. </li>\n",
    "><li>  After that there is an increase, the peak is in 2017 year.</li>\n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-04T14:43:39.018641Z",
     "iopub.status.busy": "2021-09-04T14:43:39.018074Z",
     "iopub.status.idle": "2021-09-04T14:43:39.026236Z",
     "shell.execute_reply": "2021-09-04T14:43:39.024984Z",
     "shell.execute_reply.started": "2021-09-04T14:43:39.018592Z"
    }
   },
   "source": [
    "<a id=\"sub-32\"></a>\n",
    "><div style=\"font-weight: bold;font-size:20px\">2.2 Examining features</div>\n",
    "><div style=\"font-size:16px\"> At this step we'll analyse the categorical and numeric variables</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"font-size:16px\">2.2.1 Numeric columns</div>\n",
    "Histograms, scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:02:02.125551Z",
     "iopub.status.busy": "2021-09-06T16:02:02.125084Z",
     "iopub.status.idle": "2021-09-06T16:02:03.444975Z",
     "shell.execute_reply": "2021-09-06T16:02:03.443501Z",
     "shell.execute_reply.started": "2021-09-06T16:02:02.125502Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "param_graphs = df_filtered.hist(numeric_columns, figsize=(16, 10), bins=20)\n",
    "plt.suptitle(\"Hists after removing outliers\", y=0.96, size=16)\n",
    "for axis in param_graphs.flatten():\n",
    "    axis.set_ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions  and scatter plot for each variable according to type variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:02:03.44661Z",
     "iopub.status.busy": "2021-09-06T16:02:03.446306Z",
     "iopub.status.idle": "2021-09-06T16:02:21.26208Z",
     "shell.execute_reply": "2021-09-06T16:02:21.26123Z",
     "shell.execute_reply.started": "2021-09-06T16:02:03.446581Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns_for_research = ['averageprice', 'total volume', '4046','4225','4770', 'type']\n",
    "g = sns.pairplot(data=df_filtered[columns_for_research], hue=\"type\")\n",
    "g.fig.suptitle(\"Distributions and scatter plots for each variable depending on type\", y=1.01, size=16)\n",
    "for ax in g.axes.flat: \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"font-size:16px\">2.2.2 Categorical columns</div>\n",
    "Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:02:43.853051Z",
     "iopub.status.busy": "2021-09-06T16:02:43.852361Z",
     "iopub.status.idle": "2021-09-06T16:02:43.913267Z",
     "shell.execute_reply": "2021-09-06T16:02:43.912125Z",
     "shell.execute_reply.started": "2021-09-06T16:02:43.85301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ten_largest_volume_regions = df_filtered.groupby(['region'])['total volume'].sum().sort_values(ascending=False).reset_index().head(10)\n",
    "fig = px.bar(ten_largest_volume_regions,x='region', y='total volume', title='Top ten regions with the greatest total volume over the time')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:02:21.332663Z",
     "iopub.status.busy": "2021-09-06T16:02:21.332376Z",
     "iopub.status.idle": "2021-09-06T16:02:21.534177Z",
     "shell.execute_reply": "2021-09-06T16:02:21.5329Z",
     "shell.execute_reply.started": "2021-09-06T16:02:21.332634Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_count_type = df_filtered.groupby(['price_types', 'type'])['date'].count().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='price_types', alpha=0.7, hue='type', \n",
    "                  data=df_filtered)\n",
    "plt.legend( bbox_to_anchor=(1.1, 1.1), loc='upper left')\n",
    "plt.xlabel('Price types'), plt.ylabel('Amount')\n",
    "plt.title('Relation between type and average price', size=16, y=1.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><div style=\"font-weight: bold;font-size:20px\">Observations:</div>\n",
    "><ul style=\"font-size:18px;\">\n",
    " From the lineplots above:\n",
    "><li>At the daily and monthly average price we see  a decline in price in January 2016-2017 y. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops; </li>\n",
    "><li>At the average price per year chart we see a steady decline from 2015 to 2016 y. </li>\n",
    "><li>  After that there is an increase, the peak is in 2017 year.</li>\n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sub-33\"></a>\n",
    "><div style=\"font-weight: bold;font-size:20px\">2.3 The Correlation matrix</div>\n",
    "><div style=\"font-size:16px\"> Correlation matrix depicts the correlation coefficients between all pairs of features in the data.\n",
    ">\n",
    "> We use the Pearson correlation coefficient, which is a measure of the linear association between two variables. It has a value between -1 and 1 where:\n",
    ">\n",
    "><li>-1 indicates a perfectly negative linear correlation between two variables</li>\n",
    "><li>0 indicates no linear correlation between two variables</li>\n",
    "><li>1 indicates a perfectly positive linear correlation between two variables</li></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-06T16:02:21.535802Z",
     "iopub.status.busy": "2021-09-06T16:02:21.535494Z",
     "iopub.status.idle": "2021-09-06T16:02:22.08264Z",
     "shell.execute_reply": "2021-09-06T16:02:22.081549Z",
     "shell.execute_reply.started": "2021-09-06T16:02:21.53577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# calculating the correlation matrix\n",
    "corr = df_filtered.corr()\n",
    "matrix = np.triu(corr)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, vmax=1.0, vmin=-1.0, \n",
    "            fmt='.1g', annot=True, mask = matrix)\n",
    "\n",
    "plt.title('Correlation matrix', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><div style=\"font-weight: bold;font-size:20px\">BIG observations about all the above:</div>\n",
    "><ul style=\"font-size:18px;\">\n",
    "><li>At the daily and monthly average price we see  a decline in price in January 2016-2017 y. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops; </li>\n",
    "><li>At the average price per year chart we see a steady decline from 2015 to 2016 y. </li>\n",
    "><li>  After that there is an increase, the peak is in 2017 year.</li>\n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-end\"></a>\n",
    "<div style=\"font-weight: bold;font-size:40px\">The overall conclusion</div>\n",
    "\n",
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><ul style=\"font-size:20px;\">\n",
    "\n",
    "\n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-04T13:51:53.312448Z",
     "iopub.status.busy": "2021-09-04T13:51:53.312044Z",
     "iopub.status.idle": "2021-09-04T13:51:53.327904Z",
     "shell.execute_reply": "2021-09-04T13:51:53.326448Z",
     "shell.execute_reply.started": "2021-09-04T13:51:53.312365Z"
    }
   },
   "source": [
    "<a id=\"section-end\"></a>\n",
    "<div style=\"font-size:40px\" align=center>Work in Progress\n",
    "<img src=\"https://i.pinimg.com/564x/9a/42/79/9a4279006e123929b83ad139c42c5da6.jpg\" width=50>\n",
    "\n",
    "</div>\n",
    "\n",
    "><div style=\"background-color: #FBFFEE;\">\n",
    "><ul style=\"font-size:20px;\">\n",
    " <b>Thank you</b> so much for reading my project. \n",
    " <br>Please, UPvote, if you like it or find it usefull!🍀\n",
    "\n",
    "></ul>\n",
    "></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 30292,
     "sourceId": 38613,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30120,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pattern_reg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
